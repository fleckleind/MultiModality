# Multi-Modal

<details>
<summary> ToDoList </summary>
  
```text
Flamingo
```
</details>

## Training Methodology
LLMs training methodologies typically follow one of the two strategies:
1. Light pre-training procedure and heavily relying on visual instruction tuning, as seen in the LLaVA series.
2. Extensive pre-training on large-scale, diverse datasets, followed by visual instruction fine-tuning to align with human-like interactions and safety standards, like MM1 and Idefics2.


## Zero-Shot
The definition of zero-shot task is as follow:
> A type of machine learning task in which a model is required to make predictions or perform actions on classes, tasks, or inputs that it has never seen during training.

In the context of natural language processing (NLP) or computer vision, a model is considered to be performing a zero-shot task when it is applied to new tasks or categories by leveraging pretrained knowledge and contextual reasoning, often guided by natural language prompts or semantic descriptions.
