# BLIP-2
[BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://proceedings.mlr.press/v202/li23q/li23q.pdf) 

BLIP-2: a generic and efficient pre-training strategy bootstrapping vision-language pre-trianing from off-the-shelf frozen pre-trained image encoders and frozen large language models, bridging the modality gap with a lightweight Querying Transformer pretrained in two stages.


### Vision-Language Representation Learning

### Vision-to-Language Generative Learning
