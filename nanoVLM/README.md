# nanoVLM

## Architecture
### Language Model: Qwen2.5-0.5B-Instruct


### Vision Encoder: siglip-base-patch-16-224


### Projection Layer: feature compression


## Dataset


## Trainable Parameters


## Reference
[https://nexa.ai/blogs/omni-vision](https://nexa.ai/blogs/omni-vision)  
[https://github.com/jingyaogong/minimind-v](https://github.com/jingyaogong/minimind-v)  
